{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c9e07b2",
   "metadata": {},
   "source": [
    "# PaddleOCR + LayoutLM 发票识别模型模型训练、评估和优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2fcc5b",
   "metadata": {},
   "source": [
    "### 🎯 学习目标\n",
    "> 1. 数据增强\n",
    "> 2. 模型调参\n",
    "> 3. 损失函数与优化\n",
    "> 4. 后处理优化 (正则表达式，泛化，其他模型)\n",
    "> 5. 错误分析\n",
    "> 6. 模型集成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca79c69",
   "metadata": {},
   "source": [
    "## 0. 系统架构设计\n",
    "\n",
    "我们的发票识别系统采用多阶段处理架构：\n",
    "\n",
    "```\n",
    "PDF文档 → 图像转换 → OCR文本提取 → 布局分析 → LayoutLM处理 → 信息提取 → 结构化输出\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d08dd",
   "metadata": {},
   "source": [
    "**核心组件：**\n",
    "- **PaddleOCR**: 负责文本检测和识别\n",
    "- **LayoutLM**: 理解文档布局和语义关系\n",
    "- **后处理模块**: 字段验证和格式化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803d93f",
   "metadata": {},
   "source": [
    "## 1. 数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f69bd9",
   "metadata": {},
   "source": [
    "###  PDF到图像转换\n",
    "\n",
    "**例： data_augmentation.py**\n",
    "\n",
    "**关键功能：**\n",
    "- PDF文档解析和图像转换\n",
    "- 图像质量增强（去噪、对比度调整、锐化）\n",
    "- 训练数据标注格式转换\n",
    "- 轻微旋转（±5度）\n",
    "- 亮度调整（0.8-1.2倍）\n",
    "- 对比度变化\n",
    "- 高斯噪声\n",
    "- 模糊处理\n",
    "\n",
    "**图像增强技术：**\n",
    "1. **CLAHE对比度增强**: 改善文档可读性\n",
    "2. **形态学操作**: 去除噪点和伪影\n",
    "3. **锐化滤波**: 提升文字边缘清晰度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在数据预处理阶段添加数据增强\n",
    "from data_augmentation import InvoiceDataAugmentation\n",
    "\n",
    "augmenter = InvoiceDataAugmentation()\n",
    "# 为每个训练样本生成2-3个增强版本\n",
    "augmented_images = augmenter.augment_image(image, num_augmentations=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77153c74",
   "metadata": {},
   "source": [
    "## 2. 模型调参\n",
    "\n",
    "**例： layoutlm_training.py**\n",
    "\n",
    "### 数据集构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e800b65",
   "metadata": {},
   "source": [
    "\n",
    "<mcfile name=\"layoutlm_dataset.py\" path=\"/Users/xiaotingzhou/Documents/Lectures/AI_OCR/layoutlm_dataset.py\"></mcfile> 实现了专门的数据集类：\n",
    "\n",
    "**BIO标注体系：**\n",
    "- `B-InvoiceNo`: 发票号码开始\n",
    "- `I-InvoiceNo`: 发票号码内部\n",
    "- `B-InvoiceDate`: 日期开始\n",
    "- `I-InvoiceDate`: 日期内部\n",
    "- `O`: 其他标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e16eb0f",
   "metadata": {},
   "source": [
    "### 模型训练配置\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4549f03",
   "metadata": {},
   "source": [
    "**训练参数：**\n",
    "- 学习率: 5e-5\n",
    "- 批次大小: 4\n",
    "- 训练轮数: 10\n",
    "- 权重衰减: 0.01\n",
    "\n",
    "**🔍 各参数详细说明：**\n",
    "\n",
    "1. num_train_epochs=10 : 完整训练数据集的遍历次数\n",
    "2. per_device_train_batch_size=4 : 每个GPU/CPU设备上的训练样本批次大小\n",
    "3. per_device_eval_batch_size=4 : 验证时的批次大小\n",
    "4. warmup_steps=500 : 学习率从0逐渐增加到设定值的步数\n",
    "5. weight_decay=0.01 : L2正则化系数，防止过拟合\n",
    "6. learning_rate=5e-5 : 初始学习率\n",
    "7. evaluation_strategy=\"epoch\" : 每个epoch结束后进行评估\n",
    "8. save_strategy=\"epoch\" : 每个epoch结束后保存模型\n",
    "9. metric_for_best_model=\"eval_f1\" : 使用F1分数作为最佳模型选择标准\n",
    "\n",
    "**评估指标：**\n",
    "- F1分数\n",
    "- 精确率\n",
    "- 召回率\n",
    "- 字段级准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f1b33",
   "metadata": {},
   "source": [
    "### 🚀 性能优化建议"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0704f70d",
   "metadata": {},
   "source": [
    "#### 1. 学习率优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当前配置\n",
    "learning_rate=5e-5\n",
    "\n",
    "# 优化建议：使用学习率查找或分层学习率\n",
    "learning_rate=3e-5,  # 降低学习率，提高稳定性\n",
    "# 或者使用余弦退火\n",
    "lr_scheduler_type=\"cosine\","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562672de",
   "metadata": {},
   "source": [
    "#### 2. 批次大小优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5873c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当前配置\n",
    "per_device_train_batch_size=4\n",
    "\n",
    "# 优化建议：根据GPU内存调整\n",
    "per_device_train_batch_size=8,  # 如果内存允许，增加批次大小\n",
    "gradient_accumulation_steps=2,  # 梯度累积，模拟更大批次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170a957a",
   "metadata": {},
   "source": [
    "#### 3. 训练轮数与早停优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7afd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当前配置\n",
    "num_train_epochs=10\n",
    "\n",
    "# 优化建议：增加训练轮数并使用早停\n",
    "num_train_epochs=20,\n",
    "# 在Trainer中添加早停回调\n",
    "callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a386bf",
   "metadata": {},
   "source": [
    "#### 4. 评估策略优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当前配置\n",
    "evaluation_strategy=\"epoch\"\n",
    "\n",
    "# 优化建议：更频繁的评估\n",
    "evaluation_strategy=\"steps\",\n",
    "eval_steps=200,  # 每200步评估一次\n",
    "save_steps=200,  # 每200步保存一次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8a9dd",
   "metadata": {},
   "source": [
    "#### 5. 正则化优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a9cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当前配置\n",
    "weight_decay=0.01\n",
    "\n",
    "# 优化建议：调整权重衰减\n",
    "weight_decay=0.005,  # 减少正则化强度\n",
    "# 添加dropout\n",
    "dropout=0.1,  # 在模型初始化时设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ed2bb",
   "metadata": {},
   "source": [
    "### 3. 损失函数与优化\n",
    "\n",
    "**交叉熵损失：**\n",
    "```python\n",
    "loss_fct = CrossEntropyLoss()\n",
    "loss = loss_fct(logits.view(-1, num_labels), labels.view(-1))\n",
    "```\n",
    "\n",
    "**学习率调度：**\n",
    "- 线性预热策略\n",
    "- 余弦退火调度\n",
    "- 早停机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d221962c",
   "metadata": {},
   "source": [
    "### 1. 线性预热策略 (Linear Warmup)\n",
    "#### 原理\n",
    "线性预热策略是一种学习率调度技术，在训练初期逐渐增加学习率，而不是直接使用目标学习率。\n",
    "\n",
    "#### 工作机制\n",
    "- 初始阶段 ：从很小的学习率（如0或目标学习率的1%）开始\n",
    "- 预热期 ：在预设的步数内线性增加学习率至目标值\n",
    "- 正常训练 ：达到目标学习率后按正常策略训练\n",
    "#### 优势\n",
    "- 避免梯度爆炸 ：防止训练初期大学习率导致的不稳定\n",
    "- 更好的收敛 ：让模型参数平稳地适应训练过程\n",
    "- 提高最终性能 ：特别适用于大批次训练和Transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_warmup_scheduler(step, warmup_steps, base_lr, target_lr):\n",
    "    if step < warmup_steps:\n",
    "        return base_lr + (target_lr - base_lr) * step / warmup_steps\n",
    "    return target_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cff2e8",
   "metadata": {},
   "source": [
    "### 2. 余弦退火调度 (Cosine Annealing)\n",
    "#### 原理\n",
    "余弦退火调度使用余弦函数来调整学习率，实现平滑的学习率衰减。\n",
    "\n",
    "#### 工作机制\n",
    "- 数学公式 ： lr = lr_min + (lr_max - lr_min) * (1 + cos(π * epoch / T_max)) / 2\n",
    "- 周期性变化 ：学习率按余弦曲线从最大值平滑降至最小值\n",
    "- 重启机制 ：可选择性地重启调度周期\n",
    "#### 优势\n",
    "- 平滑衰减 ：避免突然的学习率变化\n",
    "- 逃离局部最优 ：周期性重启帮助跳出局部最优解\n",
    "- 更好的泛化 ：渐进式衰减有利于模型泛化\n",
    "#### 实现示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed87102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cosine_annealing_lr(epoch, T_max, lr_max, lr_min=0):\n",
    "    return lr_min + (lr_max - lr_min) * (1 + math.cos(math.pi * epoch / T_max)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d1c62",
   "metadata": {},
   "source": [
    "### 3. 早停机制 (Early Stopping)\n",
    "#### 原理\n",
    "早停机制通过监控验证集性能，在模型开始过拟合时提前终止训练。\n",
    "\n",
    "#### 工作机制\n",
    "- 监控指标 ：通常监控验证损失或验证准确率\n",
    "- 耐心参数 ：设置连续多少个epoch性能不改善就停止\n",
    "- 最佳模型保存 ：保存验证性能最好的模型权重\n",
    "#### 优势\n",
    "- 防止过拟合 ：避免模型在训练集上过度拟合\n",
    "- 节省计算资源 ：减少不必要的训练时间\n",
    "- 自动化训练 ：无需手动判断何时停止训练\n",
    "#### 实现示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a716b",
   "metadata": {},
   "source": [
    "![Transformer Model Architecture](https://miro.medium.com/v2/resize:fit:1134/format:webp/0*z19dbRlkgocQYn6t.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584bf21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "    \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        \n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_weights = model.state_dict().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343351e2",
   "metadata": {},
   "source": [
    "## 综合应用策略\n",
    "### 组合使用\n",
    "这三种策略通常组合使用以获得最佳效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整的训练循环示例\n",
    "def train_with_optimization_strategies(model, train_loader, val_loader, epochs=100):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    # 早停机制\n",
    "    early_stopping = EarlyStopping(patience=10)\n",
    "    \n",
    "    # 学习率调度器（结合预热和余弦退火）\n",
    "    warmup_steps = len(train_loader) * 3  # 前3个epoch预热\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            # 线性预热 + 余弦退火\n",
    "            current_step = epoch * len(train_loader) + step\n",
    "            if current_step < warmup_steps:\n",
    "                lr = linear_warmup_scheduler(current_step, warmup_steps, 1e-7, 1e-4)\n",
    "            else:\n",
    "                lr = cosine_annealing_lr(current_step - warmup_steps, \n",
    "                                       total_steps - warmup_steps, 1e-4, 1e-6)\n",
    "            \n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            \n",
    "            # 训练步骤\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 验证和早停检查\n",
    "        val_loss = validate(model, val_loader)\n",
    "        if early_stopping(val_loss, model):\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008ae991",
   "metadata": {},
   "source": [
    "### 🔧 模型架构优化 （dropout）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在模型初始化时添加更多配置\n",
    "self.model = LayoutLMForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=self.num_labels,\n",
    "    hidden_dropout_prob=0.1,        # 隐藏层dropout\n",
    "    attention_probs_dropout_prob=0.1, # 注意力dropout\n",
    "    classifier_dropout=0.1,          # 分类器dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18862989",
   "metadata": {},
   "source": [
    "### 4. 后处理优化（正则表达式：Regular Expressions）\n",
    "**例： tesseract_extraction.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab891b17",
   "metadata": {},
   "source": [
    "**日期标准化：**\n",
    "```python\n",
    "def normalize_date(self, date_text):\n",
    "    chinese_pattern = r'(\\d{4})年(\\d{1,2})月(\\d{1,2})日'\n",
    "    match = re.search(chinese_pattern, date_text)\n",
    "    if match:\n",
    "        year, month, day = match.groups()\n",
    "        return f\"{year}年{month.zfill(2)}月{day.zfill(2)}日\"\n",
    "    return date_text.strip()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa14cc21",
   "metadata": {},
   "source": [
    "**金额提取：**\n",
    "```python\n",
    "def normalize_amount(self, amount_text):\n",
    "    numbers = re.findall(r'\\d+\\.?\\d*', amount_text)\n",
    "    return numbers[0] if numbers else \"0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb5070",
   "metadata": {},
   "source": [
    "## 模型评估与优化\n",
    "\n",
    "### 评估框架\n",
    "\n",
    "<mcfile name=\"model_evaluation.py\" path=\"/Users/xiaotingzhou/Documents/Lectures/AI_OCR/model_evaluation.py\"></mcfile> 提供了全面的评估工具：\n",
    "\n",
    "**评估维度：**\n",
    "- 字段级准确率\n",
    "- 整体系统性能\n",
    "- 错误类型分析\n",
    "- 置信度分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc40f1",
   "metadata": {},
   "source": [
    "## 5. 错误分析\n",
    "\n",
    "**预期性能指标：**\n",
    "- 发票号码识别: 95%+\n",
    "- 日期识别: 90%+\n",
    "- 金额识别: 95%+\n",
    "- 整体准确率: 92%+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46599eaa",
   "metadata": {},
   "source": [
    "**常见错误类型：**\n",
    "1. **OCR识别错误**: 字符混淆（如0和O）\n",
    "2. **布局理解错误**: 字段边界不准确\n",
    "3. **后处理错误**: 格式转换失败\n",
    "\n",
    "**改进策略：**\n",
    "- 增加训练数据多样性\n",
    "- 优化图像预处理\n",
    "- 改进后处理规则"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b7f99",
   "metadata": {},
   "source": [
    "**数据平衡**: 各字段样本数量均衡： Accuracy, F1, ROC_AUC, Percision,...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5e1e8",
   "metadata": {},
   "source": [
    "#### 📈 监控与调试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aff747",
   "metadata": {},
   "source": [
    "1. 使用性能监控器 ：\n",
    "   \n",
    "   - 利用 `performance_monitor.py` 监控训练性能\n",
    "2. 学习率调度 ：\n",
    "   \n",
    "   - 使用学习率查找器找到最优学习率\n",
    "   - 监控验证损失，及时调整学习率\n",
    "3. 梯度监控 ：\n",
    "   \n",
    "   - 监控梯度范数，防止梯度爆炸或消失\n",
    "### 🎯 针对文本提取的特殊优化\n",
    "1. 标签平衡 ：处理标签不平衡问题\n",
    "2. 序列长度优化 ：根据实际文档调整 max_length\n",
    "3. 位置编码 ：确保边界框坐标正确归一化\n",
    "4. 多尺度训练 ：使用不同分辨率的图像进行训练\n",
    "通过这些优化策略，您可以显著提升LayoutLM模型在发票文本提取任务上的性能和准确率。建议逐步应用这些优化，并通过验证集监控效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470cd776",
   "metadata": {},
   "source": [
    "### 6. 模型优化策略：模型集成\n",
    "\n",
    "1. **渐进式训练**: 从简单到复杂的训练策略\n",
    "2. **集成学习**: 多模型融合提升性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5bf260",
   "metadata": {},
   "source": [
    "# 集成学习在发票信息提取中的应用教学 (Ensemble Learning)\n",
    "## 概述\n",
    "集成学习通过组合多个模型来提高预测性能，在发票信息提取任务中可以显著提升准确率和鲁棒性。本教学将详细介绍Bagging、Boosting和Stacking三种方法在发票OCR中的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b78cdb9",
   "metadata": {},
   "source": [
    "## 1. Bagging（Bootstrap Aggregating 自助聚集）\n",
    "### 理论基础\n",
    "Bagging通过自助采样创建多个训练子集，训练多个模型并平均预测结果，减少方差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c157727d",
   "metadata": {},
   "source": [
    "\t•\t原理：从原始训练集通过有放回抽样（Bootstrap）生成多个子训练集；分别训练多个独立（通常是决策树）模型，再对它们输出进行平均（回归）或投票（分类）汇总 ￼。\n",
    "\t•\t好处：极大减少模型的方差，抑制过拟合，提升鲁棒性；典型应用如随机森林。\n",
    "\t•\t缺点：仅对减小方差有效，对偏差（bias）改进有限，如果基础模型关联性太高，效果有限。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671547e",
   "metadata": {},
   "source": [
    "## How Does Bagging Work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb7f54b",
   "metadata": {},
   "source": [
    "![How Does Bagging Work?](https://i0.wp.com/spotintelligence.com/wp-content/uploads/2024/03/bagging-1024x576.webp?resize=1024%2C576&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f763175",
   "metadata": {},
   "source": [
    "### ensemble_bagging_invoice.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e60d2",
   "metadata": {},
   "source": [
    "## 2. Boosting（自适应提升） XGBoost?\n",
    "### 理论基础\n",
    "Boosting通过序列化训练弱学习器，每个新模型专注于前一个模型的错误，逐步提升性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94de3a2",
   "metadata": {},
   "source": [
    "### ensemble_boosting_invoice.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad0bea",
   "metadata": {},
   "source": [
    "\t•\t原理：顺序训练一系列弱学习器，每个新模型关注纠正前一个模型的错误。常见算法 AdaBoost（自适应提升）或 Gradient Boosting（梯度提升）。\n",
    "\t•\t好处：显著减少偏差，提高模型准确性；对弱模型进行增强。\n",
    "\t•\t缺点：容易过拟合，尤其当迭代太多时；对噪声敏感，计算复杂度和时间也较大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59805c8",
   "metadata": {},
   "source": [
    "## How Does Boosting Work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d629c67a",
   "metadata": {},
   "source": [
    "![How Does Boosting Work?](https://i0.wp.com/spotintelligence.com/wp-content/uploads/2024/03/boosting-1024x576.webp?resize=1024%2C576&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f85a4e",
   "metadata": {},
   "source": [
    "## 3. Stacking（堆叠泛化）\n",
    "### 理论基础\n",
    "Stacking使用元学习器来学习如何最优地组合基础模型的预测结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62722c1c",
   "metadata": {},
   "source": [
    "### ensemble_stacking_invoice.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb730f1",
   "metadata": {},
   "source": [
    "\t•\t原理：并行训练多种不同类型的基础模型（如决策树、支持向量机等），然后将它们的预测作为特征输入给“元模型”（meta-model），由元模型学习最佳组合方式输出最终预测 ￼。\n",
    "\t•\t好处：能有效整合多种模型优势，进一步提高表现；适合结构多样的基学习器。\n",
    "\t•\t缺点：实现更复杂；训练过程耗时，计算资源要求高；解释性变差。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08362a",
   "metadata": {},
   "source": [
    "## How does Stacking Work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f9b3a",
   "metadata": {},
   "source": [
    "![How does Stacking Work?](https://i0.wp.com/spotintelligence.com/wp-content/uploads/2024/03/stacking-1024x576.webp?resize=1024%2C576&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44eb5a6",
   "metadata": {},
   "source": [
    "### 🔧 如何用 Ensemble Learning ？\n",
    "\n",
    "我们可以在多个层面使用集成策略：\n",
    "\n",
    "#### 🧩 1. 模型级集成（Model Ensemble）\n",
    "- 同时训练多个 LayoutLM 类模型（如 LayoutLMv2, LayoutXLM, Donut, TrOCR 等）\n",
    "- 对它们预测的结构化字段进行：\n",
    "- 多数投票（majority voting）\n",
    "- 置信度加权平均（confidence-weighted averaging）\n",
    "- stacking：用一个 meta-model 融合多个模型输出\n",
    "\n",
    "📌 适用场景：\n",
    "- 每个模型可能对不同字段有不同优势（如金额 vs 日期 vs 公司名）\n",
    "- 某些字段识别困难时，可融合多个模型降低误差\n",
    "\n",
    "#### 🧩 2. 输入数据增强 + Bagging\n",
    "\n",
    "- 对每张发票图片做轻微数据增强（如轻度旋转、缩放、亮度变化）\n",
    "- 生成多个 OCR 结果输入 LayoutLM\n",
    "- 对多个版本的结构化输出进行 Bagging（投票、平均）\n",
    "\n",
    "📌 优点：\n",
    "- 提高系统对噪声/格式变化的鲁棒性\n",
    "- 模拟测试集多样性，提高泛化能力\n",
    "\n",
    "\n",
    "#### 🧩 3. 多阶段 Boosting\n",
    "- 第一阶段：用轻量模型（如规则模板、keyword match）快速粗筛字段\n",
    "- 第二阶段：再用 LayoutLM 微调模型精细修正\n",
    "- 第三阶段：用规则/置信度过滤结果（如金额必须为数字、日期必须有年）\n",
    "\n",
    "📌 类似 Boosting 中「一阶段纠错一阶段」，逐层纠偏。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caaacdf",
   "metadata": {},
   "source": [
    "#### 集成学习的整体优势与注意\n",
    "\n",
    "> 优势\n",
    "\t- 综合多个模型提升性能、减少错误（bias + variance）。\n",
    "\t- 在大多数任务中显著优于单一模型 ￼。\n",
    "- 注意事项\n",
    "\t- 组合的模型必须具有多样性，才能获得协同效应()。\n",
    "\t- Boosting 的连锁误差与噪声敏感性需要谨慎控制。\n",
    "\t- Stacking 的多层结构使得调试、解释与部署更具挑战性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e3fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
