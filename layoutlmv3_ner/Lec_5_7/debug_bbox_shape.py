#!/usr/bin/env python3
"""
Debug bbox tensor shape issue
"""
import json
import torch
from src.layoutlm_trainer import LayoutLMv3Trainer, InvoiceLayoutDataset
from torch.utils.data import DataLoader

def debug_bbox_shape():
    """Debug the bbox tensor shape and values"""
    
    # Initialize trainer and dataset
    trainer = LayoutLMv3Trainer()
    train_dataset = InvoiceLayoutDataset("data/training/demo_train.json", trainer.tokenizer)
    
    print(f"ðŸ“Š æ•°æ®é›†å¤§å°: {len(train_dataset)}")
    
    # Check individual samples
    print(f"\nðŸ” æ£€æŸ¥å•ä¸ªæ ·æœ¬:")
    for i in range(3):
        sample = train_dataset[i]
        bbox = sample['bbox']
        print(f"æ ·æœ¬ {i}:")
        print(f"  bboxå½¢çŠ¶: {bbox.shape}")
        print(f"  bboxç±»åž‹: {bbox.dtype}")
        print(f"  bboxèŒƒå›´: [{bbox.min().item():.0f}, {bbox.max().item():.0f}]")
        
        # Check for values > 1000
        if bbox.max() > 1000:
            problematic_values = bbox[bbox > 1000]
            print(f"  âŒ è¶…å‡º1000çš„å€¼: {problematic_values}")
        
        # Show first few bbox values
        print(f"  å‰å‡ ä¸ªbboxå€¼: {bbox.flatten()[:10]}")
    
    # Check batched data
    print(f"\nðŸ” æ£€æŸ¥æ‰¹å¤„ç†æ•°æ®:")
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=False)
    
    for batch_idx, batch in enumerate(train_loader):
        bbox_batch = batch['bbox']
        print(f"æ‰¹æ¬¡ {batch_idx}:")
        print(f"  bboxå½¢çŠ¶: {bbox_batch.shape}")
        print(f"  bboxç±»åž‹: {bbox_batch.dtype}")
        print(f"  bboxèŒƒå›´: [{bbox_batch.min().item():.0f}, {bbox_batch.max().item():.0f}]")
        
        # Check for values > 1000
        if bbox_batch.max() > 1000:
            problematic_mask = bbox_batch > 1000
            problematic_count = problematic_mask.sum().item()
            problematic_values = bbox_batch[problematic_mask]
            print(f"  âŒ è¶…å‡º1000çš„å€¼æ•°é‡: {problematic_count}")
            print(f"  âŒ å…·ä½“å€¼: {problematic_values[:20]}")  # Show first 20
        else:
            print(f"  âœ… æ‰€æœ‰å€¼éƒ½åœ¨èŒƒå›´å†…")
        
        if batch_idx >= 2:  # Check first 3 batches
            break
    
    # Try to find the exact problematic sample
    print(f"\nðŸ” å¯»æ‰¾é—®é¢˜æ ·æœ¬:")
    for i in range(len(train_dataset)):
        sample = train_dataset[i]
        bbox = sample['bbox']
        
        if bbox.max() > 1000:
            print(f"âŒ å‘çŽ°é—®é¢˜æ ·æœ¬ {i}: bboxèŒƒå›´ [{bbox.min().item():.0f}, {bbox.max().item():.0f}]")
            
            # Get the original data
            with open("data/training/demo_train.json", 'r', encoding='utf-8') as f:
                train_data = json.load(f)
            
            # Find the corresponding data sample
            sample_count = 0
            for item in train_data:
                if sample_count == i:
                    print(f"åŽŸå§‹æ•°æ®:")
                    print(f"  å›¾åƒ: {item['image_path']}")
                    for j, entity in enumerate(item['entities'][:3]):
                        print(f"  å®žä½“ {j}: '{entity['text']}' bbox={entity['bbox']}")
                    break
                sample_count += len(item['entities'])
                if sample_count > i:
                    break
        
        if i >= 50:  # Don't check all samples, just first 50
            break

if __name__ == '__main__':
    debug_bbox_shape()